{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib.parse\n",
    "import json\n",
    "import pandas as pd\n",
    "from requests_html import HTMLSession\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "def _get_source(url: str):\n",
    "\n",
    "    try:\n",
    "        session = HTMLSession()\n",
    "        user_agents = [\n",
    "            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.121 Safari/537.36',\n",
    "            'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:81.0) Gecko/20100101 Firefox/81.0',\n",
    "            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0 Safari/605.1.15',\n",
    "            'Mozilla/5.0 (Linux; Android 10; SM-G975F) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.198 Mobile Safari/537.36',\n",
    "            'Mozilla/5.0 (iPhone; CPU iPhone OS 14_2 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0 Mobile/15E148 Safari/604.1'\n",
    "        ]\n",
    "        user_agent = random.choice(user_agents)\n",
    "        \n",
    "        session.headers.update({'User-Agent': user_agent})\n",
    "        response = session.get(url)\n",
    "\n",
    "        return response\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(e)\n",
    "\n",
    "\n",
    "def _get_results(query: str):\n",
    "\n",
    "    query = urllib.parse.quote_plus(query)\n",
    "    response = _get_source(\"https://suggestqueries.google.com/complete/search?output=chrome&hl=de&q=\" + query)\n",
    "    \n",
    "    results = json.loads(response.text)\n",
    "    return results\n",
    "\n",
    "\n",
    "def _format_results(results: dict):\n",
    "\n",
    "    if results:\n",
    "        suggestions = []\n",
    "        for index, value in enumerate(results[1]):\n",
    "            suggestion = {'term': value, 'relevance': results[4]['google:suggestrelevance'][index]}\n",
    "            suggestions.append(suggestion)\n",
    "        return suggestions\n",
    "\n",
    "\n",
    "def _get_suggestions(query: str):\n",
    "    results = _get_results(query)\n",
    "    results = _format_results(results)\n",
    "    results = sorted(results, key=lambda k: k['relevance'], reverse=True)\n",
    "    return results\n",
    "\n",
    "\n",
    "def _get_expanded_term_suffixes():\n",
    "\n",
    "    expanded_term_suffixes = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm',\n",
    "                              'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
    "\n",
    "    return expanded_term_suffixes\n",
    "\n",
    "\n",
    "def _get_expanded_term_prefixes():\n",
    "\n",
    "    expanded_term_prefixes = ['wer ist *', 'was ist *', 'wo ist *', 'wann kann *', 'warum ist *',\n",
    "                            'wie man *', 'beste', 'günstig', 'schlechteste', 'ist', 'was', 'wann',\n",
    "                            'warum', 'wie', 'wer']\n",
    "\n",
    "    \n",
    "    return expanded_term_prefixes\n",
    "\n",
    "\n",
    "def _get_expanded_terms(query: str):\n",
    "\n",
    "    expanded_term_prefixes = _get_expanded_term_prefixes()\n",
    "    expanded_term_suffixes = _get_expanded_term_suffixes()\n",
    "\n",
    "    terms = [query]\n",
    "\n",
    "    for term in expanded_term_prefixes:\n",
    "        terms.append(term + ' ' + query)\n",
    "\n",
    "    for term in expanded_term_suffixes:\n",
    "        terms.append(query + ' ' + term)\n",
    "\n",
    "    return terms\n",
    "\n",
    "\n",
    "def _get_expanded_suggestions(query: str):\n",
    "    all_results = []\n",
    "\n",
    "    expanded_terms = _get_expanded_terms(query)\n",
    "    for term in expanded_terms:\n",
    "        results = _get_results(term)\n",
    "        results = _format_results(results)\n",
    "        all_results = all_results + results\n",
    "        all_results = sorted(all_results, key=lambda k: k['relevance'], reverse=True)\n",
    "    return all_results\n",
    "\n",
    "\n",
    "def google_autocomplete(query: str, include_expanded=True):\n",
    "    if include_expanded:\n",
    "        results = _get_expanded_suggestions(query)\n",
    "\n",
    "    else:\n",
    "        results = _get_suggestions(query)\n",
    "\n",
    "    df = pd.DataFrame.from_records(results)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "related_keywords = [ #data 1 hdbscan_model = HDBSCAN(min_cluster_size=20, min_samples=20, prediction_data=True, gen_min_span_tree=True)\n",
    "   'brille',\n",
    "   \"brillen\",\n",
    "   \"optiker\",\n",
    "   \"Aigner United Ooptics\",\n",
    "   \"United Ooptics\",\n",
    "   \n",
    "] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brillenmarke\n",
      "sehhilfen\n",
      "brillenvergleich\n",
      "brillenmode\n",
      "brillenangebot\n",
      "brillen\n",
      "brillenglas\n",
      "fahrbrille\n",
      "brilleninnovation\n",
      "brillenstil\n",
      "glasreparatur\n",
      "modebrillen\n",
      "brilleonline\n",
      "brillenanpassung\n",
      "sehstärke\n",
      "sichtgläser\n",
      "kontaktlinsenpflege\n",
      "brillenfürsportler\n",
      "sonnenbrille\n",
      "sehhilfenfürkinder\n",
      "brillenservice\n",
      "optiker\n",
      "brillenblog\n",
      "kontaktlinsen\n",
      "brillenhersteller\n",
      "brillenetui\n",
      "brillenauswahl\n",
      "gläser\n",
      "fassungen\n",
      "lesebrille\n",
      "optiken\n",
      "lesebrillen\n",
      "augenoptik\n",
      "brillenverleih\n",
      "sportbrillen\n",
      "schutzglas\n",
      "sicherheitsbrille\n",
      "sonnenbrillen\n",
      "brilleninspiration\n",
      "brillenreview\n",
      "brillenfassung\n",
      "brillenkollektionen\n",
      "brillenaccessoires\n",
      "brillenkollektion\n",
      "augenarzt\n",
      "brillencommunity\n",
      "schwimmbrille\n",
      "optische gläser\n",
      "brillengestell\n",
      "brillenreiniger\n",
      "gleitsichtbrille\n",
      "skibrille\n",
      "augenpflege\n",
      "korrigierende brille\n",
      "brillenzubehör\n",
      "sicherheitsbrillen\n",
      "sehhilfe\n",
      "brillendesign\n",
      "schutzbrille\n",
      "brillenfarbe\n",
      "kinderbrille\n",
      "designerbrille\n",
      "brillenrabatt\n",
      "brillenputztuch\n",
      "arbeitsbrille\n",
      "dioptrien\n",
      "brillenversicherung\n",
      "brillenpromotion\n",
      "lupe\n",
      "linsen\n",
      "brillenband\n",
      "computerbrille\n",
      "optik\n",
      "brillenfashion\n",
      "brillentrends\n",
      "modebrille\n",
      "taucherbrille\n",
      "glas\n",
      "brillenreinigung\n",
      "brillenverkauf\n",
      "brillenpflege\n",
      "brillenberatung\n",
      "brillenmaterial\n",
      "sichtbrille\n",
      "brillentrend\n",
      "brille\n",
      "sportbrille\n",
      "fassung\n",
      "augenschutz\n",
      "lesehilfe\n",
      "brillenreparatur\n",
      "brillenversand\n",
      "brillengläser\n"
     ]
    }
   ],
   "source": [
    "all_suggestions = []  \n",
    "\n",
    "for keyword in related_keywords:\n",
    "  print(keyword)\n",
    "  try:\n",
    "    suggestions = google_autocomplete(keyword, include_expanded=True)\n",
    "\n",
    "    df = pd.DataFrame(suggestions)\n",
    "    all_suggestions.append(df)\n",
    "  except:\n",
    "    continue\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_dataframe = pd.concat(all_suggestions, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "import nltk\n",
    "from bertopic import BERTopic\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gute Ergebnisse:\n",
    "'umap_model': UMAP(min_dist=0.03, n_components=3, n_neighbors=3, tqdm_kwds={'bar_format': '{desc}: {percentage:3.0f}%| {bar} \n",
    "\n",
    "\n",
    "\n",
    "'hdbscan_model': HDBSCAN(gen_min_span_tree=True, min_cluster_size=10, min_samples=5,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_model = UMAP(n_neighbors=3, n_components=3, min_dist=0.03)\n",
    "hdbscan_model = HDBSCAN(min_cluster_size=10, min_samples=5, prediction_data=True, gen_min_span_tree=True) # Kann bearbeitet werden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = list(stopwords.words(\"german\"))\n",
    "\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "vectorizer_model = CountVectorizer(ngram_range=(1, 2), stop_words=stopwords)\n",
    "\n",
    "model = BERTopic(\n",
    "    umap_model=umap_model,\n",
    "    hdbscan_model=hdbscan_model,\n",
    "    embedding_model=embedding_model,\n",
    "    vectorizer_model=vectorizer_model,\n",
    "    top_n_words=5,\n",
    "    language=\"german\",\n",
    "    calculate_probabilities=True,\n",
    "    verbose=True\n",
    "    )\n",
    "\n",
    "topics, probs = model.fit_transform(big_dataframe[\"term\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/MaartenGr/BERTopic\n",
    "\n",
    "TF-IDF: https://www.youtube.com/watch?v=vZAXpvHhQow&t=423s&ab_channel=DataScienceGarage\n",
    "\n",
    "Code (BERTopic): https://www.youtube.com/watch?v=fb7LENb9eag&ab_channel=JamesBriggs\n",
    "Code (API): https://github.com/practical-data-science/ecommercetools#7-get-keyword-suggestions-from-google-autocomplete\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
